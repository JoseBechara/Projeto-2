{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Antônio Fonseca\n",
    "\n",
    "Nome: José Bechara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@JosAntnioBecha2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Dados de autenticação do twitter:\n",
    "\n",
    "# #Coloque aqui o identificador da conta no twitter: @JosAntnioBecha2 \n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'tesla'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capturando os dados do twitter:\n",
    "** (Já evitando mensagens repetidas) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Cria um objeto para a captura\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "# #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#     # Evitando mensagens repitidas:\n",
    "#     if msg not in msgs: \n",
    "#         msgs.append(msg.full_text.lower())\n",
    "#         i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "# #Embaralhando as mensagens para reduzir um possível viés\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "#     #Abre o arquivo para escrita\n",
    "#     writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "#     #divide o conjunto de mensagens em duas planilhas\n",
    "#     dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#     dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#     dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#     dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "#     #fecha o arquivo\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando o DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deletar_caracteres(coluna):\n",
    "    coluna = coluna.replace(\"https://\",\"\").replace(\".\",\" \").replace(\":\",\" \").replace(\",\",\" \").replace(\"'\",\" \")\\\n",
    "    .replace('\"', \" \").replace(\"#\",\"\").replace(\"-\",\"\").replace(\"•\", \"\").replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \")\\\n",
    "    .replace(\"—\", \" \").replace(\"rt\", \"\").replace(\"?\", \" \").replace(\"!\", \" \").replace(\"/\",\"\").replace(\";\", \" \")\\\n",
    "    .replace(\"{\", \"\").replace(\"}\", \"\").replace(\"|\",\"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"_\", \"\")\\\n",
    "    .replace(\"__\", \"\").replace(\"\\\\\",\"\").replace(\"´\", \"\").replace(\"ˆ\",\"\").replace(\"˜\",\"\").replace(\"\\\\\", \" \\\\\").replace(\"U+\", \" U+\")\n",
    "    return coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_emoji(em):\n",
    "    \n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(em)\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "    return em_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treinamento = pd.read_excel(produto + \".xlsx\", sheet_name= \"Treinamento\")\n",
    "Teste = pd.read_excel(produto +\".xlsx\", sheet_name= \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treinamento['Treinamento'] = Treinamento['Treinamento'].apply(deletar_caracteres)\n",
    "Teste[\"Teste\"] = Teste[\"Teste\"].apply(deletar_caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relevante = Treinamento[Treinamento[\"Classificação\"]==1]\n",
    "tx_relevante = \" \".join(relevante.Treinamento)\n",
    "tx_relevante = tx_relevante.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "irrelevante= Treinamento[Treinamento[\"Classificação\"]==2]\n",
    "tx_irrelevante = \" \".join(irrelevante.Treinamento)\n",
    "tx_irrelevante = tx_irrelevante.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_relevante = pd.Series(separa_emoji(tx_relevante))\n",
    "# serie_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tesla            145\n",
       "de               107\n",
       "a                 90\n",
       "um                88\n",
       "o                 79\n",
       "t                 75\n",
       "que               67\n",
       "da                57\n",
       "e                 47\n",
       "no                32\n",
       "com               31\n",
       "é                 30\n",
       "carro             28\n",
       "em                27\n",
       "mais              24\n",
       "do                24\n",
       "não               23\n",
       "ser               21\n",
       "elon              21\n",
       "musk              20\n",
       "por               18\n",
       "vai               18\n",
       "elétrica          17\n",
       "pickup            17\n",
       "se                16\n",
       "eu                15\n",
       "carros            15\n",
       "para              14\n",
       "ao                14\n",
       "os                14\n",
       "                ... \n",
       "ponto              1\n",
       "tass               1\n",
       "observador         1\n",
       "ntsb               1\n",
       "fiquei             1\n",
       "@craigdrawsyt      1\n",
       "@zzziizuka         1\n",
       "morrem             1\n",
       "valendo            1\n",
       "facilitar          1\n",
       "pessoas            1\n",
       "@eusouzarolho      1\n",
       "nossas             1\n",
       "mãos               1\n",
       "avon               1\n",
       "aumenta            1\n",
       "@slendyzo          1\n",
       "sobre              1\n",
       "bosta              1\n",
       "propostas          1\n",
       "energia            1\n",
       "@nicotp            1\n",
       "perfect            1\n",
       "difícil            1\n",
       "cog8nz0n5tii       1\n",
       "mal                1\n",
       "caminhão           1\n",
       "péssimas           1\n",
       "dessa              1\n",
       "defeitos           1\n",
       "Length: 1109, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relevante = serie_relevante.value_counts()\n",
    "d_lista_relev= tabela_relevante[1]\n",
    "tabela_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante_relativa = serie_relevante.value_counts(True)\n",
    "# tabela_relevante_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_irrelevante = pd.Series(separa_emoji(tx_irrelevante))\n",
    "#serie_irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrelevante = serie_irrelevante.value_counts()\n",
    "d_lista_irrelev= tabela_irrelevante[1]\n",
    "###tabela_irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrelevante_relativa = serie_irrelevante.value_counts(True)\n",
    "# tabela_irrelevante_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavra): \n",
    "    if palavra in tabela_relevante:\n",
    "        k = tabela_relevante[palavra]\n",
    "    else:\n",
    "        k = 0\n",
    "    if palavra in tabela_irrelevante:\n",
    "        J = tabela_irrelevante[palavra]\n",
    "    else:\n",
    "        J = 0\n",
    "    prob_relev = (k +1)/(len(serie_relevante) + d_lista_relev)\n",
    "    prob_irrelev = (J + 1)/(len(serie_irrelevante) + d_lista_irrelev) \n",
    "    return [prob_relev, prob_irrelev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_frase(frase):\n",
    "    f = str(frase.lower())\n",
    "    f = separa_emoji(f)\n",
    "    coeficiente_relevante = 1\n",
    "    coeficiente_irrelevante = 1\n",
    "    for e in f:\n",
    "        coeficiente_relevante *= probabilidade(e)[0]\n",
    "        coeficiente_irrelevante *= probabilidade(e)[1]\n",
    "        \n",
    "    if coeficiente_relevante >= coeficiente_irrelevante:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "# print (prob_frase(\"se quiseres compreender o segredo do universo, pense em energia, frequência e vibração. tesla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = []\n",
    "for e in Teste[\"Teste\"]:\n",
    "    k.append(prob_frase(e))\n",
    "Teste[\"Simulação\"] = k    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "falso_pos = 0\n",
    "neg = 0\n",
    "falso_neg = 0\n",
    "total = len(Teste[\"Classificação\"])\n",
    "\n",
    "for [e,i] in zip(Teste[\"Classificação\"], Teste[\"Simulação\"]):\n",
    "    if e == 1:\n",
    "        if i == 1:\n",
    "            pos += 1\n",
    "        else: \n",
    "            falso_neg += 1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            neg +=1\n",
    "        else:\n",
    "            falso_pos +=1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros relevantes:  37.0 %\n",
      "Falsos relevantes:  8.5 %\n",
      "Verdadeiros irrelevantes:  36.5 %\n",
      "Falsos irrelevantes:  18.0 %\n",
      "___________________________________\n",
      "Acertos:  73.5 %\n",
      "Erros:  26.5 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Verdadeiros relevantes: \", round((pos/total)*100,2), \"%\")\n",
    "print(\"Falsos relevantes: \", round((falso_pos/total)*100, 2), \"%\")\n",
    "print(\"Verdadeiros irrelevantes: \", round((neg/total)*100,2), \"%\")\n",
    "print(f\"Falsos irrelevantes: \", round((falso_neg/total)*100, 2), \"%\")\n",
    "print(\"_\"*35)\n",
    "\n",
    "print(\"Acertos: \", round(((pos/total)+(neg/total))*100,2), \"%\")\n",
    "print(\"Erros: \", round(((falso_pos/total)+(falso_neg/total))*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "irrel = 0\n",
    "rel = 0\n",
    "for e in Teste[\"Classificação\"]:\n",
    "    if e==1:\n",
    "        rel +=1\n",
    "    else:\n",
    "        irrel +=1\n",
    "        \n",
    "print(irrel/len(Teste[\"Teste\"]))    \n",
    "print(rel/len(Teste[\"Teste\"]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o código rodar a cada hora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 300\n",
    "# while True:\n",
    "#     #Cria um objeto para a captura\n",
    "#     api = tweepy.API(auth)\n",
    "\n",
    "#     #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "#     i = 1\n",
    "#     msgs = []\n",
    "#     for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#         # Evitando mensagens repitidas:\n",
    "#         if msg not in msgs: \n",
    "#             msgs.append(msg.full_text.lower())\n",
    "#             i += 1\n",
    "#         if i > n:\n",
    "#             break\n",
    "#     dft = pd.DataFrame({'Teste' : pd.Series(msgs)})\n",
    "#     dft[\"Teste\"] = Teste[\"Teste\"].apply(deletar_caracteres)\n",
    "#     dft.dropna(inplace=True)\n",
    "#     k = []\n",
    "#     for e in dft[\"Teste\"]:\n",
    "#         k.append(prob_frase(e))\n",
    "#     dft[\"Simulação\"] = k \n",
    "# #     print(dft)\n",
    "\n",
    "#     irrel = 0\n",
    "#     rel = 0\n",
    "#     for e in Teste[\"Classificação\"]:\n",
    "#         if e==1:\n",
    "#             rel +=1\n",
    "#         else:\n",
    "#             irrel +=1\n",
    "#     print(f\"relevantes: {round(rel/(rel+irrel),2)} irrelevantes: {round(irrel/(rel+irrel),2)}\")\n",
    "#     sleep(60**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link para separação dos Emojis:\n",
    "<br>\n",
    "https://stackoverflow.com/questions/49921720/how-to-split-emoji-from-each-other-python    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link para remoção de caracteres:\n",
    "<br>\n",
    "https://pt.stackoverflow.com/questions/217832/como-retirar-caractere-especial-e-ponto-de-coluna-string-de-um-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
