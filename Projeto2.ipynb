{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Antônio Fonseca\n",
    "\n",
    "Nome: José Bechara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import emoji\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@JosAntnioBecha2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Dados de autenticação do twitter:\n",
    "\n",
    "# #Coloque aqui o identificador da conta no twitter: @JosAntnioBecha2 \n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'tesla'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capturando os dados do twitter:\n",
    "** (Já evitando mensagens repetidas) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Cria um objeto para a captura\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "# #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "# i = 1\n",
    "# msgs = []\n",
    "# for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#     # Evitando mensagens repitidas:\n",
    "#     if msg not in msgs: \n",
    "#         msgs.append(msg.full_text.lower())\n",
    "#         i += 1\n",
    "#     if i > n:\n",
    "#         break\n",
    "\n",
    "# #Embaralhando as mensagens para reduzir um possível viés\n",
    "# shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "# if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "#     #Abre o arquivo para escrita\n",
    "#     writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "#     #divide o conjunto de mensagens em duas planilhas\n",
    "#     dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "#     dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "#     dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "#     dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "#     #fecha o arquivo\n",
    "#     writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Esta etapa é manual. Faça a mesma pelo Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando o DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletar_caracteres(coluna):\n",
    "    coluna = coluna.replace(\"https://\",\"\").replace(\".\",\" \").replace(\":\",\" \").replace(\",\",\" \").replace(\"'\",\" \")\\\n",
    "    .replace('\"', \" \").replace(\"#\",\"\").replace(\"-\",\"\").replace(\"•\", \"\").replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \")\\\n",
    "    .replace(\"—\", \" \").replace(\"rt\", \"\").replace(\"?\", \" \").replace(\"!\", \" \").replace(\"/\",\"\").replace(\";\", \" \")\\\n",
    "    .replace(\"{\", \"\").replace(\"}\", \"\").replace(\"|\",\"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"_\", \"\")\\\n",
    "    .replace(\"__\", \"\").replace(\"\\\\\",\"\").replace(\"´\", \"\").replace(\"ˆ\",\"\").replace(\"˜\",\"\").replace(\"\\\\\", \" \\\\\")\\\n",
    "    .replace(\"U+\", \" U+\")\n",
    "    return coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_emoji(em):\n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(em)\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "    return em_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treinamento = pd.read_excel(produto + \".xlsx\", sheet_name= \"Treinamento\")\n",
    "Teste = pd.read_excel(produto +\".xlsx\", sheet_name= \"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Treinamento['Treinamento'] = Treinamento['Treinamento'].apply(deletar_caracteres)\n",
    "Teste[\"Teste\"] = Teste[\"Teste\"].apply(deletar_caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relevante = Treinamento[Treinamento[\"Classificação\"]==1]\n",
    "tx_relevante = \" \".join(relevante.Treinamento)\n",
    "tx_relevante = tx_relevante.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "irrelevante= Treinamento[Treinamento[\"Classificação\"]==2]\n",
    "tx_irrelevante = \" \".join(irrelevante.Treinamento)\n",
    "tx_irrelevante = tx_irrelevante.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O produto escolhido foi a marca Tesla Motors, avaliamos os tweets em 2 categorias (RELEVANTE e IRRELEVANTE). O critério usado para a classificação foi relativamente simples, uma vez que \"Tesla\" pode se referir a outras coisas como o inventor famoso Nikola Tesla, que não tem relação alguma com a marca Tesla. \n",
    "<br>\n",
    "Por exemplo:**\n",
    "<br>\n",
    "- *\"rt @anlotulys: \"se quiseres compreender o segredo do universo, pense em energia, frequência e vibração.\" tesla\"*\n",
    "<br> \n",
    "\n",
    "Esse tweet foi marcado como IRRELEVANTE, pois se refere ao Nikola Tesla e não a marca Tesla.\n",
    "<br>\n",
    "**Já o tweet:**\n",
    "<br>\n",
    "- *\"o preço de tesla coloca ele como um carro de luxo.\"*\n",
    "<br> \n",
    "\n",
    "Foi marcado como RELEVANTE, pois se refere a marca Tesla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_relevante = pd.Series(separa_emoji(tx_relevante))\n",
    "# serie_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante = serie_relevante.value_counts()\n",
    "d_lista_relev= tabela_relevante[1]\n",
    "# tabela_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante_relativa = serie_relevante.value_counts(True)\n",
    "# tabela_relevante_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_irrelevante = pd.Series(separa_emoji(tx_irrelevante))\n",
    "#serie_irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrelevante = serie_irrelevante.value_counts()\n",
    "d_lista_irrelev= tabela_irrelevante[1]\n",
    "###tabela_irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_irrelevante_relativa = serie_irrelevante.value_counts(True)\n",
    "# tabela_irrelevante_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavra): \n",
    "    if palavra in tabela_relevante:\n",
    "        k = tabela_relevante[palavra]\n",
    "    else:\n",
    "        k = 0\n",
    "    if palavra in tabela_irrelevante:\n",
    "        J = tabela_irrelevante[palavra]\n",
    "    else:\n",
    "        J = 0\n",
    "    prob_relev = (k +1)/(len(serie_relevante) + d_lista_relev)\n",
    "    prob_irrelev = (J + 1)/(len(serie_irrelevante) + d_lista_irrelev) \n",
    "    return [prob_relev, prob_irrelev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_frase(frase):\n",
    "    f = str(frase.lower())\n",
    "    f = separa_emoji(f)\n",
    "    coeficiente_relevante = 1\n",
    "    coeficiente_irrelevante = 1\n",
    "    for e in f:\n",
    "        coeficiente_relevante *= probabilidade(e)[0]\n",
    "        coeficiente_irrelevante *= probabilidade(e)[1]\n",
    "        \n",
    "    if coeficiente_relevante >= coeficiente_irrelevante:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "# print (prob_frase(\"se quiseres compreender o segredo do universo, pense em energia, frequência e vibração. tesla\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = []\n",
    "for e in Teste[\"Teste\"]:\n",
    "    k.append(prob_frase(e))\n",
    "Teste[\"Simulação 1\"] = k   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "falso_pos = 0\n",
    "neg = 0\n",
    "falso_neg = 0\n",
    "total = len(Teste[\"Classificação\"])\n",
    "irrel = 0\n",
    "rel = 0\n",
    "\n",
    "for [e,i] in zip(Teste[\"Classificação\"], Teste[\"Simulação 1\"]):\n",
    "    if e == 1:\n",
    "        if i == 1:\n",
    "            pos += 1\n",
    "        else: \n",
    "            falso_neg += 1\n",
    "    if e == 2:            \n",
    "        if i == 2:\n",
    "            neg +=1\n",
    "        else:\n",
    "            falso_pos +=1        \n",
    "            \n",
    "for e in Teste[\"Classificação\"]:\n",
    "    if e==1:\n",
    "        rel +=1\n",
    "    else:\n",
    "        irrel +=1            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros relevantes:  37.0 %\n",
      "Falsos relevantes:  8.5 %\n",
      "Verdadeiros irrelevantes:  36.5 %\n",
      "Falsos irrelevantes:  18.0 %\n",
      "_______________________________________________________\n",
      "Acertos:  73.5 %\n",
      "Erros:  26.5 %\n",
      "_______________________________________________________\n",
      "Tweets classificados manualmente como relevantes: 55.0 %\n",
      "Tweets classificados manualmente como irrelevantes: 45.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Verdadeiros relevantes: \", round((pos/total)*100,2), \"%\")\n",
    "print(\"Falsos relevantes: \", round((falso_pos/total)*100, 2), \"%\")\n",
    "print(\"Verdadeiros irrelevantes: \", round((neg/total)*100,2), \"%\")\n",
    "print(f\"Falsos irrelevantes: \", round((falso_neg/total)*100, 2), \"%\")\n",
    "print(\"_\"*55)\n",
    "\n",
    "print(\"Acertos: \", round(((pos/total)+(neg/total))*100,2), \"%\")\n",
    "print(\"Erros: \", round(((falso_pos/total)+(falso_neg/total))*100,2), \"%\")\n",
    "print(\"_\"*55)\n",
    "\n",
    "\n",
    "print(\"Tweets classificados manualmente como relevantes:\", 100*rel/len(Teste[\"Teste\"]), \"%\")\n",
    "print(\"Tweets classificados manualmente como irrelevantes:\", 100*irrel/len(Teste[\"Teste\"]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o código rodar a cada hora:\n",
    "tirar os \"#\" para habilitar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 300\n",
    "# simulacao = 1\n",
    "# while True:\n",
    "#     simulacao +=1\n",
    "#     #Cria um objeto para a captura\n",
    "#     api = tweepy.API(auth)\n",
    "\n",
    "#     #Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "#     i = 1\n",
    "#     msgs = []\n",
    "#     for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "#         # Evitando mensagens repitidas:\n",
    "#         if msg not in msgs: \n",
    "#             msgs.append(msg.full_text.lower())\n",
    "#             i += 1\n",
    "#         if i > n:\n",
    "#             break\n",
    "#     dft = pd.DataFrame({'Teste' : pd.Series(msgs)})\n",
    "#     dft[\"Teste\"] = Teste[\"Teste\"].apply(deletar_caracteres)\n",
    "#     dft.dropna(inplace=True)\n",
    "#     k = []\n",
    "#     for e in dft[\"Teste\"]:\n",
    "#         k.append(prob_frase(e))\n",
    "#     Teste[\"Simulação {0}\".format(simulacao)] = k \n",
    "\n",
    "#     irrel = 0\n",
    "#     rel = 0\n",
    "#     for e in Teste[\"Classificação\"]:\n",
    "#         if e==1:\n",
    "#             rel +=1\n",
    "#         else:\n",
    "#             irrel +=1\n",
    "# #     print(f\"relevantes: {round(rel/(rel+irrel),2)} irrelevantes: {round(irrel/(rel+irrel),2)}\")\n",
    "#     print(Teste.head())\n",
    "#     sleep(60*15) #15 minutos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros relevantes:  37.0 %\n",
      "Falsos relevantes:  8.5 %\n",
      "Verdadeiros irrelevantes:  36.5 %\n",
      "Falsos irrelevantes:  18.0 %\n",
      "_______________________________________________________\n",
      "Acertos:  73.5 %\n",
      "Erros:  26.5 %\n",
      "_______________________________________________________\n",
      "Tweets classificados manualmente como relevantes: 55.0 %\n",
      "Tweets classificados manualmente como irrelevantes: 45.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Verdadeiros relevantes: \", round((pos/total)*100,2), \"%\")\n",
    "print(\"Falsos relevantes: \", round((falso_pos/total)*100, 2), \"%\")\n",
    "print(\"Verdadeiros irrelevantes: \", round((neg/total)*100,2), \"%\")\n",
    "print(f\"Falsos irrelevantes: \", round((falso_neg/total)*100, 2), \"%\")\n",
    "print(\"_\"*55)\n",
    "\n",
    "print(\"Acertos: \", round(((pos/total)+(neg/total))*100,2), \"%\")\n",
    "print(\"Erros: \", round(((falso_pos/total)+(falso_neg/total))*100,2), \"%\")\n",
    "print(\"_\"*55)\n",
    "\n",
    "\n",
    "print(\"Tweets classificados manualmente como relevantes:\", 100*rel/len(Teste[\"Teste\"]), \"%\")\n",
    "print(\"Tweets classificados manualmente como irrelevantes:\", 100*irrel/len(Teste[\"Teste\"]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Como impresso novamente na célula a cima, notamos uma taxa que julgamos boa de acertos por parte de nosso algorítimo, de 73.5%, e analisando por grupo de relevância, temos proporções muito próximas entre relevantes e irrelevantes nas avaliações feitas manualmente e pelo Naive-Bayes (55% de relevantes na avaliação manual e 45% pelo Naive-Bayes) concluindo não haver nenhuma tendência sistêmica de direcionamento por parte do algorítmo.\n",
    "    Uma falha encontrada no desenvolver do projeto foi ao implementarmos uma função que separava os \"emojis\" e os considerava cada um uma palavra, a taxa de acerto do código diminuiu em pouco menos de 5%, possivalmente em virtude de uma maior repetição de uma palavra (normalmente emojis são usados em sequencia entao passam a ter uma frequencia muito maior com a nova função) influencia diretamente no cálculo do Naive-Bayes en suas próximas ocorrências.\n",
    "    Como modo de ampliação e aprofundamento do projeto deveria ser implementado um sistema capaz de interpreetar duplas negativas, sinais de ironia e principalmente entender \"erros de ortografia\" e variações à norma padrão, cabendo também o acrescimo de mais categorias dentro do grupo \"relevante\" de forma a dicernir reais preferências do usuário à respeito do produto analizado.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não podemos fazer isso por causa da propagação de erro, se temos 70% de acurácia ao usarmos esse mesmo classificador para aumentar a base de dados significará que apenas 70% das mensagens novas estarão classificadas corretamente, e portanto o classificador treinará com mensagens classificadas equivocadamente e diminuirá a acurácia do classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Propor diferentes cenários para Naïve Bayes fora do contexto do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar o Naive Bayes para sistemas de reconhecimento de imagem, por exemplo fazer um programa que reconhece números e letras escritos a mão em imagens. Para fazer isso usamos o os pixels das imagens em \"grayscale\" com o vetor posição de cada um. \n",
    "\n",
    "$$\n",
    "P(c|x) = \\frac{P(x | c)P(c)}{P(x)}\n",
    "$$\n",
    "\n",
    "Onde \"x\" representa a informação dada e \"c\" a classe que a representa, no caso \"x\" seria o pixel vetorizado e \"c\" o caracter.\n",
    "<br>\n",
    "Porém para calcular o $ P(c)$ não temos como somar todos os pixels de todas as imagens, por isso usamos a forma normal multivariada em escala logarítimica.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link para separação dos Emojis:\n",
    "<br>\n",
    "https://stackoverflow.com/questions/49921720/how-to-split-emoji-from-each-other-python    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link para remoção de caracteres:\n",
    "<br>\n",
    "https://pt.stackoverflow.com/questions/217832/como-retirar-caractere-especial-e-ponto-de-coluna-string-de-um-data-frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outras aplicações do Naive Bayes:\n",
    "<br>\n",
    "https://www.quora.com/In-what-real-world-applications-is-Naive-Bayes-classifier-used\n",
    "<br>\n",
    "https://lazyprogrammer.me/bayes-classifier-and-naive-bayes-tutorial-using/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
